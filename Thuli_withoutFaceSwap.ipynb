{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Installing all the necessary libs"
      ],
      "metadata": {
        "id": "5_BOLkKXFlAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YFd4J89PcPW",
        "outputId": "636b0120-ca53-4b46-8c1d-8b97cc17b2d6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (3.4.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.10.0.84)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->mtcnn) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->mtcnn) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->mtcnn) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->mtcnn) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->mtcnn) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->mtcnn) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->mtcnn) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=2.0.0->mtcnn) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=2.0.0->mtcnn) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.0.0->mtcnn) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.0.0->mtcnn) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->mtcnn) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKEQyYLE0pJ5",
        "outputId": "b5d09c80-f100-4f6a-a122-1b719404e03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgV-Cv2U-rd4",
        "outputId": "762df753-3174-4b48-893c-4ead13e2a4d5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qdrant-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNgVg1QE_efm",
        "outputId": "d4374786-d512-406f-8131-5d35f4eef346"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qdrant-client\n",
            "  Downloading qdrant_client-1.11.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.64.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
            "  Downloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting httpx>=0.20.0 (from httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.26.4)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.9.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client)\n",
            "  Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting grpcio>=1.41.0 (from qdrant-client)\n",
            "  Downloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (71.0.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (4.12.2)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
            "Downloading qdrant_client-1.11.3-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.9/258.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: protobuf, portalocker, hyperframe, hpack, h11, grpcio, httpcore, h2, grpcio-tools, httpx, qdrant-client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.64.1\n",
            "    Uninstalling grpcio-1.64.1:\n",
            "      Successfully uninstalled grpcio-1.64.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.66.2 grpcio-tools-1.66.2 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.6 httpx-0.27.2 hyperframe-6.0.1 portalocker-2.10.1 protobuf-5.28.2 qdrant-client-1.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJc4QJSa8TZi"
      },
      "source": [
        "# Feature extraction using ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Getting the face dataset from kaggle"
      ],
      "metadata": {
        "id": "sHvf5jyL7gOo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "5oaBz7BSyq2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4150adfe-96a5-42b1-dbca-f3d1a74e1553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-KYCG-2y2tn",
        "outputId": "58883114-4a20-4291-82fa-0db895df58c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/sushilyadav1998/bollywood-celeb-localized-face-dataset\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "bollywood-celeb-localized-face-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d sushilyadav1998/bollywood-celeb-localized-face-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting the dataset"
      ],
      "metadata": {
        "id": "nNVPwRVU72fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "i6YBkJgYzKBs"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/bollywood-celeb-localized-face-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing the necessary libs"
      ],
      "metadata": {
        "id": "TmOfop9a8Ai1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "9Wr4Hokk7W0c"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.preprocessing.image as image\n",
        "from PIL import Image\n",
        "from keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.applications.efficientnet import preprocess_input\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from keras.applications import VGG16\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the pretrained model and its waits by removing the final layer to extract features"
      ],
      "metadata": {
        "id": "PYkt88SS8Hs7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "-BClbAmeGUxr"
      },
      "outputs": [],
      "source": [
        "model = ResNet50(include_top=False, input_shape=(224, 224, 3), pooling='avg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Saving the model as a keras file for laters use"
      ],
      "metadata": {
        "id": "b4fiB5ER6dzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/extractor.keras')"
      ],
      "metadata": {
        "id": "HqkZeNGr66Dl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function to extract features from each photo"
      ],
      "metadata": {
        "id": "xwsXoS8M-IHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "wgfAgsx2MfUM"
      },
      "outputs": [],
      "source": [
        "def featureExtraction(path, model):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    imgArr = image.img_to_array(img)\n",
        "    imgArrE = np.expand_dims(imgArr, axis=0)\n",
        "    preImg = preprocess_input(imgArrE)\n",
        "    result = model.predict(preImg).flatten()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating file folders for each photo in the dataset"
      ],
      "metadata": {
        "id": "eHocn9-E-Vcp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "NKq7Nz-eNeva"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Bollywood_celeb_face_localized'\n",
        "folders = os.listdir(path)\n",
        "\n",
        "filenames = []\n",
        "for folder in folders:\n",
        "    for actor in os.listdir(os.path.join(path, folder)):\n",
        "        for file in os.listdir(os.path.join(path, folder, actor)):\n",
        "            filenames.append(os.path.join(path, folder, actor, file))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grouping the files according to the actors"
      ],
      "metadata": {
        "id": "CgbwoDja_USL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQx_HjZ2NhB5",
        "outputId": "e6d5a099-03e9-4861-8ed7-d1f0ba94feb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8674/8674 [00:00<00:00, 513093.29it/s]\n"
          ]
        }
      ],
      "source": [
        "groupedFiles = {}\n",
        "for file in tqdm(filenames):\n",
        "    parts = file.split('/')\n",
        "    if parts[6] not in groupedFiles:\n",
        "        groupedFiles[parts[6]] = []\n",
        "    groupedFiles[parts[6]].append(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting the feature of every photo"
      ],
      "metadata": {
        "id": "FTkzVQrgHeJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "for file in tqdm(filenames):\n",
        "    features.append(featureExtraction(file, model))"
      ],
      "metadata": {
        "id": "zeMaaUInE5qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dumping the extracted features in a file"
      ],
      "metadata": {
        "id": "G_JCp_rfHu9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('embedding.pickle', 'wb') as file:\n",
        "    pickle.dump(features, file, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "2AKPtxdUHvST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei1jHwNjQUV5"
      },
      "source": [
        "#Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function that uses gradCAM to interpret the features extracted by the model"
      ],
      "metadata": {
        "id": "i91eppS6EBkG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O03299C3RbGj"
      },
      "outputs": [],
      "source": [
        "def gradCAM(model, imgArr, layer):\n",
        "    gradModel = Model([model.inputs], [model.get_layer(layer).output, model.output])\n",
        "    with tensorflow.GradientTape() as tape:\n",
        "            convOutputs, predictions = gradModel(imgArr)\n",
        "            loss = predictions[:, 0]\n",
        "\n",
        "    grads = tape.gradient(loss, convOutputs)\n",
        "    pooledGrads = K.mean(grads, axis=(0, 1, 2))\n",
        "    convOutputs = convOutputs[0]\n",
        "    heatmap = tensorflow.reduce_mean(tensorflow.multiply(pooledGrads, convOutputs), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= tensorflow.math.reduce_max(heatmap)\n",
        "\n",
        "    return heatmap.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting the pre-loaded features"
      ],
      "metadata": {
        "id": "t7M5cSPxG9Wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting the features from the pickle because this was used at a later time"
      ],
      "metadata": {
        "id": "Y-OF7T-yCu-m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "TQZy507QBRxM"
      },
      "outputs": [],
      "source": [
        "with open('embedding.pkl', 'rb') as file:\n",
        "    data = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###List of all female actors in the dataset"
      ],
      "metadata": {
        "id": "gIZWre_UC2MB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4HDkLwGSXndj"
      },
      "outputs": [],
      "source": [
        "female = ['Aishwarya_Rai', 'Alia_Bhatt', 'Ameesha_Patel', 'Amrita_Rao', 'Amy_Jackson', 'Anushka_Sharma', 'Anushka_Shetty', 'Asin', 'Bhumi_Pednekar', 'Bipasha_Basu', 'Deepika_Padukone', 'Disha_Patani', 'Esha_Gupta', 'Huma_Qureshi', 'Ileana_DCruz', 'Jacqueline_Fernandez', 'Juhi_Chawla', 'Kajal_Aggarwal', 'Kajol', 'Kangana_Ranaut', 'Kareena_Kapoor', 'Karisma_Kapoor', 'Katrina_Kaif', 'Kiara_Advani', 'Kriti_Kharbanda', 'Kriti_Sanon', 'Lara_Dutta', 'Madhuri_Dixit', 'Mrunal_Thakur', 'Nargis_Fakhri', 'Nushrat_Bharucha', 'Parineeti_Chopra', 'Pooja_Hegde', 'Prachi_Desai', 'Preity_Zinta', 'Priyanka_Chopra', 'Rani_Mukerji', 'Richa_Chadda', 'Sara_Ali_Khan', 'Shilpa_Shetty', 'Shraddha_Kapoor', 'Shruti_Haasan', 'Sonakshi_Sinha', 'Sonam_Kapoor', 'Taapsee_Pannu', 'Tabu', 'Tamannaah_Bhatia', 'Vaani_Kapoor', 'Vidya_Balan', 'Yami_Gautam', 'Zareen_Khan']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting the features of the female actors from the total dataset"
      ],
      "metadata": {
        "id": "uKvp9gRCC-jA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "d3Aa7PX2Giqz"
      },
      "outputs": [],
      "source": [
        "i = list(enumerate(data))\n",
        "positions = []\n",
        "for pos in i:\n",
        "    positions.append(list(pos)[0])\n",
        "\n",
        "femaleFiles = {}\n",
        "\n",
        "for pos in positions:\n",
        "    if filenames[pos].split('/')[6] in female:\n",
        "        if filenames[pos].split('/')[6] not in femaleFiles:\n",
        "            femaleFiles[filenames[pos].split('/')[6]] = []\n",
        "        femaleFiles[filenames[pos].split('/')[6]].extend([i[pos][1]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"femaleData.pickle\", \"rb\") as file:\n",
        "    femaleFiles = pickle.load(file)"
      ],
      "metadata": {
        "id": "Hrf1m090C0uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Finding the average of the features of each female actor"
      ],
      "metadata": {
        "id": "ybuFXyt5DmJm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "9mt4YXOKKqpX"
      },
      "outputs": [],
      "source": [
        "avgFemaleFiles = {}\n",
        "for actor in femaleFiles:\n",
        "    avgFemaleFiles[actor] = np.mean(femaleFiles[actor], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dumping the featuers of the female actors in a pickle file to be inserted into the dataset"
      ],
      "metadata": {
        "id": "Z5thT2NmDVI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPGDLW9KhU0p"
      },
      "outputs": [],
      "source": [
        "with open(\"femaleData.pickle\", \"wb\") as file:\n",
        "    pickle.dump(femaleFiles, file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "M75PEffsNBB3"
      },
      "outputs": [],
      "source": [
        "with open(\"avgFemaleData.pickle\", \"wb\") as file:\n",
        "    pickle.dump(avgFemaleFiles, file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdEavdaIl5-U"
      },
      "source": [
        "# Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty3t2GQShXcd",
        "outputId": "84660e99-1dd2-43d2-b09b-49d930b62c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.74.225.24\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Getting the api-key and url for qdrant db"
      ],
      "metadata": {
        "id": "OHne19fxB1BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "import numpy as np\n",
        "import uuid\n",
        "\n",
        "# Initialize the Qdrant client\n",
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://de5011c8-153d-497d-945c-4fe99eb2c8b7.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=\"SScBhK7-cfyJ3lPxSYVbkFUozuCFcj37PAtoiS7NIOAMMYAxRPPFJg\",\n",
        ")"
      ],
      "metadata": {
        "id": "TxMkvf_Axmek"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Streamlit app that gets the input image, vein color, measurement to find the similar actresses and then the color of the dress according to the skintone"
      ],
      "metadata": {
        "id": "o6Zq8ijUA5e7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx_Qx2_vgfrb",
        "outputId": "743ef269-466e-48bd-8655-493664cd78cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "import requests\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.preprocessing.image as image\n",
        "from PIL import Image\n",
        "from keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.applications.efficientnet import preprocess_input\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from keras.applications import VGG16\n",
        "from mtcnn import MTCNN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from qdrant_client import QdrantClient, models\n",
        "import uuid\n",
        "\n",
        "\n",
        "if 'image_uploaded' not in st.session_state:\n",
        "    st.session_state['image_uploaded'] = False\n",
        "\n",
        "if 'show_options' not in st.session_state:\n",
        "    st.session_state['show_options'] = False\n",
        "\n",
        "if 'show_measurements' not in st.session_state:\n",
        "    st.session_state['show_measurements'] = False\n",
        "\n",
        "\n",
        "pageByImg = \"\"\"\n",
        "<style>\n",
        "[data-testid=\"stSidebar\"] {\n",
        "    background-image: url(\"https://i.pinimg.com/736x/d3/58/da/d358dad037688a32e20a6994b66bf053.jpg\");\n",
        "    background-size: cover\n",
        "}\n",
        "\n",
        "[data-testid=\"stHeader\"] {\n",
        "background: rgba(0,0,0,0);\n",
        "}\n",
        "\n",
        ".option-box {\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "        height: 150px;\n",
        "        width: 100%;\n",
        "        background-color: #4CAF50;\n",
        "        color: white;\n",
        "        font-size: 24px;\n",
        "        font-weight: bold;\n",
        "        border-radius: 10px;\n",
        "        text-align: center;\n",
        "        cursor: pointer;\n",
        "        margin-bottom: 20px;\n",
        "        transition: transform 0.2s, background-color 0.3s;\n",
        "    }\n",
        "\n",
        ".option-box:hover {\n",
        "    background-color: #45a049;\n",
        "    transform: scale(1.05);\n",
        "}\n",
        "\n",
        ".option-box p {\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "API_KEY = 'AIzaSyBeAT2lsfSDgPTEkTyO5pKw4FIcbMv_67Y'\n",
        "SEARCH_ENGINE_ID = 'a6dd3ca0c5cb94454'\n",
        "\n",
        "def print_images(query, limit=5):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=API_KEY)\n",
        "\n",
        "    response = service.cse().list(\n",
        "        q=query,\n",
        "        cx=SEARCH_ENGINE_ID,\n",
        "        searchType='image',\n",
        "        num=min(limit, 10)\n",
        "    ).execute()\n",
        "\n",
        "    img_urls = []\n",
        "    for index, item in enumerate(response.get('items', [5]), start=1):\n",
        "        img_url = item['link']\n",
        "        img_urls.append(img_url)\n",
        "    return img_urls\n",
        "\n",
        "def get_base64_of_bin_file(bin_file):\n",
        "    with open(bin_file, 'rb') as f:\n",
        "        data = f.read()\n",
        "    return base64.b64encode(data).decode()\n",
        "\n",
        "def find_closest_point(query_vector, top_k=2):\n",
        "    # Search for the nearest point in the specified collection\n",
        "    # Initialize the Qdrant client\n",
        "    qdrant_client = QdrantClient(\n",
        "    url=\"https://de5011c8-153d-497d-945c-4fe99eb2c8b7.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=\"SScBhK7-cfyJ3lPxSYVbkFUozuCFcj37PAtoiS7NIOAMMYAxRPPFJg\",)\n",
        "    search_result = qdrant_client.search(\n",
        "        collection_name= \"celebrity_collection\",\n",
        "        query_vector=query_vector.tolist(),  # Convert NumPy array to list\n",
        "        limit=top_k  # Limit the number of results\n",
        "    )\n",
        "\n",
        "    if search_result:\n",
        "        for point in search_result:  # Iterate over the search result\n",
        "            st.write(f\"Closest point payload: {point.payload}\")  # Print payload (name)\n",
        "            actress = point.payload\n",
        "            st.write(f\"Cosine similarity: {point.score}\")  # Print distance\n",
        "    else:\n",
        "        st.write(\"No points found in the collection.\")\n",
        "    return actress\n",
        "\n",
        "def set_png_as_page_bg(png_file=None):\n",
        "    page_bg_img = '''\n",
        "    <style>\n",
        "    .stApp {\n",
        "    background-image: url(\"https://t4.ftcdn.net/jpg/06/34/09/69/360_F_634096945_nT013AXOaokOmXXU0mRlfSLmnSbbmZXw.jpg\");\n",
        "    background-size: cover;\n",
        "    background-repeat: no-repeat;\n",
        "    }\n",
        "    </style>\n",
        "    '''\n",
        "\n",
        "    st.markdown(page_bg_img, unsafe_allow_html=True)\n",
        "    return\n",
        "\n",
        "set_png_as_page_bg()\n",
        "st.markdown(pageByImg, unsafe_allow_html=True)\n",
        "st.markdown('<h1 style=\"color:black;\">MET \\u0BA4\\u0BBF\\u0BB0\\u0BC1\\u0BB5\\u0BBF\\u0BB4\\u0BBe</h1>', unsafe_allow_html=True)\n",
        "model = load_model(\"/content/drive/MyDrive/extractor.keras\")\n",
        "detector = MTCNN()\n",
        "\n",
        "undertone = {'Purple': 'cool', 'Green': 'warm', 'Blue': 'cool', 'Mix': 'Neutral'}\n",
        "udTone = 'Neutral'\n",
        "toneToCol = {'warm': ['red', 'orange', 'gold', 'magenta', 'amber', 'peacock blue', 'coral', 'olive', 'honey'],\n",
        "             'cool': ['blue', 'royal blue', 'bright blue', 'gray', 'rose', 'lavender', 'deep purple', 'bright rose', 'emerald', 'amethyst', 'ruby'],\n",
        "             'neutral': ['pink', 'white', 'off-white', 'cream', 'taupe']}\n",
        "\n",
        "upload= st.file_uploader('Upload your image', type=['png','jpg'])\n",
        "c1, c2 = st.columns(2)\n",
        "if upload is not None:\n",
        "    im= Image.open(upload)\n",
        "    img= np.asarray(im)\n",
        "    image= cv2.resize(img,(224, 224))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = detector.detect_faces(img)\n",
        "    x, y, width, height = results[0]['box']\n",
        "    rect = plt.Rectangle((x, y), width, height, fill=False, color='green')\n",
        "    face = img[y:y+height, x:x+width]\n",
        "    test = Image.fromarray(face)\n",
        "    test = test.resize((224, 224))\n",
        "    testArr = np.asarray(test).astype('float32')\n",
        "    exp = np.expand_dims(testArr, axis=0)\n",
        "    preExp = preprocess_input(exp)\n",
        "    result = model.predict(preExp).flatten()\n",
        "    c1.header('Input Image')\n",
        "    c1.image(im)\n",
        "    st.session_state['show_options'] = True\n",
        "\n",
        "if st.session_state['show_options']:\n",
        "    st.write('---')\n",
        "    st.title(\"Choose your vein colour\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    options = [\"BLUE\", \"PURPLE\", \"GREEN\", \"OTHERS\"]\n",
        "    if 'selected_option' not in st.session_state:\n",
        "        st.session_state['selected_option'] = None\n",
        "\n",
        "# Step 3: Create the option boxes and allow selection\n",
        "    with col1:\n",
        "        if st.button(\"BLUE\", key=\"opt1\"):\n",
        "            st.session_state['selected_option'] = \"Blue\"\n",
        "        #st.markdown('<div class=\"option-box\"><p>Option 1</p></div>', unsafe_allow_html=True)\n",
        "\n",
        "        if st.button(\"PURPLE\", key=\"opt3\"):\n",
        "            st.session_state['selected_option'] = \"Purple\"\n",
        "        #st.markdown('<div class=\"option-box\"><p>Option 3</p></div>', unsafe_allow_html=True)\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"GREEN\", key=\"opt2\"):\n",
        "            st.session_state['selected_option'] = \"Green\"\n",
        "        #st.markdown('<div class=\"option-box\"><p>Option 2</p></div>', unsafe_allow_html=True)\n",
        "\n",
        "        if st.button(\"MIX\", key=\"opt4\"):\n",
        "            st.session_state['selected_option'] = \"Mix\"\n",
        "        #st.markdown('<div class=\"option-box\"><p>Option 4</p></div>', unsafe_allow_html=True)\n",
        "\n",
        "    if st.session_state['selected_option'] is not None:\n",
        "        udTone = undertone[st.session_state['selected_option']]\n",
        "        st.title(f\"You have {undertone[st.session_state['selected_option']]} undertones\")\n",
        "        st.session_state['show_measurements'] = True\n",
        "\n",
        "if st.session_state['show_measurements']:\n",
        "    st.write('---')\n",
        "    st.title('Enter your measurements: ')\n",
        "    #st.markdown('<h5 style=\"color:black;\">Enter bust size</h5>', unsafe_allow_html=True)\n",
        "    bust = st.number_input(\"Enter bust size\",key=\"bust\")\n",
        "    #st.markdown('<h5 style=\"color:black;\">Enter waist size</h5>', unsafe_allow_html=True)\n",
        "    waist = st.number_input(\"Enter waist size\",key=\"waist\")\n",
        "    #st.markdown('<h5 style=\"color:black;\">Enter hip size</h5>', unsafe_allow_html=True)\n",
        "    hip = st.number_input(\"Enter hip size\",key=\"hip\")\n",
        "\n",
        "    if bust>0 and waist>0 and hip>0:\n",
        "        if abs(bust-hip)<2 and (bust-waist)>=7:\n",
        "            queryVec = np.concatenate((result, np.array([0, 1, 0, 0])))\n",
        "        elif hip>bust:\n",
        "            queryVec = np.concatenate((result, np.array([0, 0, 1, 0])))\n",
        "        elif bust>hip:\n",
        "            queryVec = np.concatenate((result, np.array([1, 0, 0, 0])))\n",
        "        else:\n",
        "            queryVec = np.concatenate((result, np.array([0, 0, 0, 1])))\n",
        "\n",
        "        actress = find_closest_point(queryVec)\n",
        "        color = toneToCol[udTone][0]\n",
        "        urls = print_images(f\"{actress} posing alone in {color} ethnic wear\")\n",
        "        response = requests.get(urls[0])\n",
        "        image_data = np.frombuffer(response.content, np.uint8)\n",
        "        finalImg = cv2.imdecode(image_data, cv2.IMREAD_COLOR)\n",
        "        cv2.imwrite(\"actress.jpg\", finalImg)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cells necessary to make streamlit run on google colab"
      ],
      "metadata": {
        "id": "6otDM0m1CD8S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "tVhnYPc8grZU"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbgEeMAQh9uf",
        "outputId": "82010477-36bb-4af0-9345-208aec179f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://some-breads-float.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qHNkirfdl-h1",
        "ei1jHwNjQUV5",
        "5SyoQ_68YPyv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}